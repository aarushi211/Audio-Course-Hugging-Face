


import librosa


array, sampling_rate = librosa.load(librosa.ex("trumpet"))


array


sampling_rate


import matplotlib.pyplot as plt
import librosa.display


plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)





import numpy as np


dft_input = array[:4096] # first 4096 samples. Length of first note


window = np.hanning(len(dft_input))
windowed_input = dft_input * window
dft = np.fft.rfft(windowed_input)


# get the amplitude spectrum in decibels
amplitude = np.abs(dft)
amplitude_db = librosa.amplitude_to_db(amplitude, ref=np.max)


# get the frequency bins
frequency = librosa.fft_frequencies(sr=sampling_rate, n_fft=len(dft_input))

plt.figure().set_figwidth(12)
plt.plot(frequency, amplitude_db)
plt.xlabel("Frequency (Hz)")
plt.ylabel("Amplitude (dB)")
plt.xscale("log")





D = librosa.stft(array)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)


plt.figure().set_figwidth(12)
librosa.display.specshow(S_db, x_axis="time", y_axis="hz")
plt.colorbar()





S = librosa.feature.melspectrogram(y=array, sr=sampling_rate, n_mels=128, fmax=8000)


S_dB = librosa.power_to_db(S, ref=np.max)


plt.figure().set_figwidth(12)
librosa.display.specshow(S_dB, x_axis="time", y_axis="mel", sr=sampling_rate, fmax=8000)
plt.colorbar()





from datasets import load_dataset


minds = load_dataset("PolyAI/minds14", name="en-AU", split="train", trust_remote_code=True)
minds


example = minds[0]
example


id2label = minds.features["intent_class"].int2str
id2label(example["intent_class"])


columns_to_remove = ["lang_id", "english_transcription"]
minds = minds.remove_columns(columns_to_remove)
minds


import gradio as gr


def generate_audio():
    example = minds.shuffle()[0]
    audio = example["audio"]
    return (
        audio["sampling_rate"],
        audio["array"],
    ), id2label(example["intent_class"])


with gr.Blocks() as demo:
    with gr.Column():
        for _ in range(4):
            audio, label = generate_audio()
            output = gr.Audio(audio, label=label)

demo.launch(debug=True)


import librosa
import matplotlib.pyplot as plt
import librosa.display

array = example["audio"]["array"]
sampling_rate = example["audio"]["sampling_rate"]

plt.figure().set_figwidth(12)
librosa.display.waveshow(array, sr=sampling_rate)





from datasets import Audio

minds = minds.cast_column("audio", Audio(sampling_rate=16_000))


minds[0]


MAX_DURATION_IN_SECONDS = 20.0

def is_audio_length_in_range(input_length):
    return input_length < MAX_DURATION_IN_SECONDS


# We don't have a duration column in the dataset. So we are creating that
new_column = [librosa.get_duration(path=x) for x in minds["path"]]
minds = minds.add_column("duration", new_column)


minds


minds = minds.filter(is_audio_length_in_range, input_columns=["duration"])


minds = minds.remove_columns(["duration"])
minds


from transformers import WhisperFeatureExtractor

feature_extractor = WhisperFeatureExtractor.from_pretrained("openai/whisper-small")


def prepare_dataset(example):
    audio = example["audio"]
    features = feature_extractor(
        audio["array"], sampling_rate=audio["sampling_rate"], padding=True
    )
    return features


minds = minds.map(prepare_dataset)
minds


import numpy as np

example = minds[0]
input_features = example["input_features"]

plt.figure().set_figwidth(12)
librosa.display.specshow(
    np.asarray(input_features[0]),
    x_axis="time",
    y_axis="mel",
    sr=feature_extractor.sampling_rate,
    hop_length=feature_extractor.hop_length,
)
plt.colorbar()


from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("openai/whisper-small")





gigaspeech = load_dataset("PolyAI/minds14", "en-AU", streaming=True)


# Can't directly use indexing to access data. Need to iterate the data
next(iter(gigaspeech["train"]))


# To preview more samples use take. It will give the first n elements
gigaspeech_head = gigaspeech["train"].take(2)
list(gigaspeech_head)
